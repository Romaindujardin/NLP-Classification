{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "589afdc4",
      "metadata": {},
      "source": [
        "# Modèle final (LSTM Bidirectionnal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7d8e4c",
      "metadata": {},
      "source": [
        "### Sommaire :\n",
        "* Importation des packages\n",
        "* Importation des données\n",
        "* PRÉTRAITEMENT : VECTORISATION DU TEXTE\n",
        "* CRÉATION DU DATASET TENSORFLOW\n",
        "* CONSTRUCTION ET ENTRAÎNEMENT DU MODÈLE\n",
        "* PRÉDICTIONS ET ÉVALUATIONS INITIALES\n",
        "* CALCUL DES MÉTRIQUES AVEC KERAS\n",
        "* CALCUL DES MÉTRIQUES AVEC SKLEARN\n",
        "* SAUVEGARDE ET CHARGEMENT DU MODÈLE\n",
        "* FONCTION DE SCORING D'UN COMMENTAIRE\n",
        "* ÉVALUATION COMPLÉMENTAIRE AVEC ACCURACY_SCORE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031ada14",
      "metadata": {},
      "source": [
        "# Importation des packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2e3037",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import des modules Keras et sklearn\n",
        "from tensorflow.keras.layers import TextVectorization, LSTM, Dropout, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb031f9",
      "metadata": {},
      "source": [
        "# 1. Importation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00afbf59",
      "metadata": {},
      "source": [
        "Ajoutez un raccourci de ce dossier à votre google drive :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c1ff101",
      "metadata": {},
      "source": [
        "https://drive.google.com/drive/folders/1mx-CAzT10YKrmxHfYDP_1Oef7PVGUr7s?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9116d213",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importez le module de lecteur de Google.colab pour interagir avec Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Montez Google Drive vers le répertoire '/Content/Drive'\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7cfb528",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importation des données d'entraînement à partir de Google Drive\n",
        "data = pd.read_csv('/Users/romain/Downloads/Classification/data_classification_commentaires_toxiques/train.csv')\n",
        "\n",
        "# Affichage rapide du dataframe pour vérifier les données importées\n",
        "print(data)\n",
        "\n",
        "# Affichage d'un exemple de commentaire toxique pour la classe 'identity_hate'\n",
        "print(data.loc[data.identity_hate == 1].iloc[0].comment_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cd48d33",
      "metadata": {},
      "source": [
        "# 2. PRÉTRAITEMENT : VECTORISATION DU TEXTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3969f0fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sélection des commentaires et des labels\n",
        "x = data.comment_text  # Texte des commentaires\n",
        "y = data[data.columns[2:]].values  # Labels des différentes classes de toxicité\n",
        "\n",
        "# Définition du nombre maximum de caractéristiques (mots) à prendre en compte\n",
        "max_words = 200000\n",
        "\n",
        "# Initialisation du TextVectorization pour transformer le texte en séquences d'entiers\n",
        "vectorizer = TextVectorization(max_tokens=max_words,\n",
        "                               output_sequence_length=2000,\n",
        "                               output_mode='int')\n",
        "\n",
        "# Adapter le vectoriseur sur les données textuelles pour apprendre le vocabulaire\n",
        "vectorizer.adapt(x.values)\n",
        "\n",
        "# Affichage de la taille du vocabulaire appris\n",
        "print(\"Taille du vocabulaire :\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "# Exemple de vectorisation d'un texte\n",
        "print(\"Exemple de vectorisation :\", vectorizer('Hello world, my name is Dualingo'))\n",
        "\n",
        "# Conversion de tous les commentaires en séquences vectorisées\n",
        "vectorized_text = vectorizer(x.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a449287",
      "metadata": {},
      "source": [
        "# 3. CRÉATION DU DATASET TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b282df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création d'un dataset TensorFlow à partir des données vectorisées et des labels\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "# Mise en cache du dataset pour améliorer les performances\n",
        "dataset = dataset.cache()\n",
        "# Mélange des données pour garantir que les batches sont aléatoires\n",
        "dataset = dataset.shuffle(160000)\n",
        "# Division des données en batches de taille 16\n",
        "dataset = dataset.batch(16)\n",
        "# Préchargement des données pour améliorer les performances d'entraînement\n",
        "dataset = dataset.prefetch(8)\n",
        "\n",
        "# Affichage d'un batch pour vérification\n",
        "batch_x, batch_y = dataset.as_numpy_iterator().next()\n",
        "print(\"Shape d'un batch (x):\", batch_x.shape)\n",
        "print(\"Shape d'un batch (y):\", batch_y.shape)\n",
        "\n",
        "# Division du dataset en ensembles d'entraînement, validation et test\n",
        "total_batches = len(dataset)\n",
        "train = dataset.take(int(total_batches * 0.7))  # 70% pour l'entraînement\n",
        "val = dataset.skip(int(total_batches * 0.7)).take(int(total_batches * 0.2))  # 20% pour la validation\n",
        "test = dataset.skip(int(total_batches * 0.9)).take(int(total_batches * 0.1))  # 10% pour le test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfdace94",
      "metadata": {},
      "source": [
        "# 4. CONSTRUCTION ET ENTRAÎNEMENT DU MODÈLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2995bdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création d'un modèle séquentiel\n",
        "model = Sequential()\n",
        "# Ajout d'une couche d'embedding pour convertir les indices de mots en vecteurs denses\n",
        "model.add(Embedding(max_words + 1, 32))\n",
        "# Ajout d'une couche LSTM bidirectionnelle pour capturer les dépendances dans les deux directions\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "# Ajout de couches denses avec activation ReLU pour l'apprentissage des caractéristiques complexes\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Ajout de la couche de sortie avec activation sigmoïde pour les prédictions binaires sur 6 classes\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "# Affichage du résumé du modèle pour vérifier l'architecture\n",
        "model.summary()\n",
        "\n",
        "# Compilation du modèle avec une fonction de perte binaire et l'optimiseur Adam\n",
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement avec validation sur les données de validation\n",
        "history = model.fit(train, epochs=20, validation_data=val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba0f810",
      "metadata": {},
      "source": [
        "# 5. PRÉDICTIONS ET ÉVALUATIONS INITIALES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8729ab9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prédiction sur un exemple de texte\n",
        "input_text = vectorizer('You are so dumbt! if i see you, you are dead')\n",
        "print(\"Prédiction (exemple 1) :\", model.predict(np.array([input_text])))\n",
        "print(\"Prédiction (exemple 2) :\", model.predict(np.expand_dims(input_text, 0)))\n",
        "\n",
        "# Evaluation sur un batch du test set\n",
        "batch_x, batch_y = test.as_numpy_iterator().next()\n",
        "print(\"Prédictions sur batch test :\", (model.predict(batch_x) > 0.5).astype(int))\n",
        "print(\"Labels réels :\", batch_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb62fb7",
      "metadata": {},
      "source": [
        "# 6. CALCUL DES MÉTRIQUES AVEC KERAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e850bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialisation des métriques de précision et de rappel\n",
        "precision = Precision()\n",
        "recall = Recall()\n",
        "\n",
        "# Boucle sur chaque batch du jeu de données de test\n",
        "for batch in test.as_numpy_iterator():\n",
        "    batch_x, batch_y = batch\n",
        "    # Prédiction des labels pour le batch courant\n",
        "    yhat = model.predict(batch_x)\n",
        "    # Aplatir les tableaux pour le calcul des métriques\n",
        "    precision.update_state(batch_y.flatten(), yhat.flatten())\n",
        "    recall.update_state(batch_y.flatten(), yhat.flatten())\n",
        "\n",
        "# Calcul des résultats finaux pour la précision et le rappel\n",
        "precision = precision.result().numpy()\n",
        "recall = recall.result().numpy()\n",
        "# Calcul du F1-score à partir de la précision et du rappel\n",
        "f1score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-score: {f1score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91bee3f4",
      "metadata": {},
      "source": [
        "# 7. CALCUL DES MÉTRIQUES AVEC SKLEARN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d07debf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialisation des listes pour stocker les vraies étiquettes et les prédictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Boucle sur chaque batch du jeu de données de test\n",
        "for batch in test.as_numpy_iterator():\n",
        "    batch_x, batch_y = batch\n",
        "    # Prédiction des labels pour le batch courant\n",
        "    yhat = model.predict(batch_x)\n",
        "    # Ajout des vraies étiquettes et des prédictions aux listes\n",
        "    y_true.append(batch_y)\n",
        "    y_pred.append(yhat)\n",
        "\n",
        "# Conversion des listes en tableaux numpy\n",
        "y_true = np.vstack(y_true)\n",
        "y_pred = np.vstack(y_pred)\n",
        "\n",
        "# Seuil de 0.5 pour binariser les prédictions\n",
        "y_pred_bin = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calcul des métriques par label\n",
        "precision_per_label = precision_score(y_true, y_pred_bin, average=None)\n",
        "recall_per_label = recall_score(y_true, y_pred_bin, average=None)\n",
        "f1_per_label = f1_score(y_true, y_pred_bin, average=None)\n",
        "\n",
        "# Affichage des résultats par label\n",
        "print(f\"Precision par label: {precision_per_label}\")\n",
        "print(f\"Recall par label: {recall_per_label}\")\n",
        "print(f\"F1-score par label: {f1_per_label}\")\n",
        "\n",
        "# Calcul des F1-scores globaux\n",
        "f1_macro = f1_score(y_true, y_pred_bin, average=\"macro\")\n",
        "f1_micro = f1_score(y_true, y_pred_bin, average=\"micro\")\n",
        "\n",
        "# Affichage des F1-scores globaux\n",
        "print(f\"F1-score macro (moyenne): {f1_macro}\")\n",
        "print(f\"F1-score micro (global): {f1_micro}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95cc77bf",
      "metadata": {},
      "source": [
        "# 8. SAUVEGARDE ET CHARGEMENT DU MODÈLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32c8afa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# sauvegarde du modele\n",
        "model.save('Final_LSTM.h5')\n",
        "# chargement du modele\n",
        "model = tf.keras.models.load_model('Final_LSTM.h5')\n",
        "print(\"Modèle chargé :\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e96bf84",
      "metadata": {},
      "source": [
        "# 9. FONCTION DE SCORING D'UN COMMENTAIRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef90db2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def score_comment(comment):\n",
        "    # Vectorisation du commentaire pour le transformer en séquence d'entiers\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    \n",
        "    # Prédiction des probabilités de toxicité pour chaque classe\n",
        "    results = model.predict(vectorized_comment)\n",
        "    \n",
        "    # Initialisation d'une chaîne de caractères pour stocker les résultats\n",
        "    text = \"\"\n",
        "    \n",
        "    # Boucle sur chaque classe de toxicité pour formater les résultats\n",
        "    for idx, col in enumerate(data.columns[2:]):\n",
        "        # Ajout du nom de la classe et du résultat de la prédiction (True si > 0.5, sinon False)\n",
        "        text += f'{col}: {results[0][idx] > 0.5}\\n'\n",
        "    \n",
        "    # Retourne le texte formaté avec les résultats\n",
        "    return text\n",
        "\n",
        "# Exemple d'utilisation de la fonction avec un commentaire toxique\n",
        "print(score_comment(\"FUCK YOU\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5620032c",
      "metadata": {},
      "source": [
        "# 10. ÉVALUATION COMPLÉMENTAIRE AVEC ACCURACY_SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a921d821",
      "metadata": {},
      "outputs": [],
      "source": [
        "# bout de code pour pouvoir évaluer des phrases seuls, suffit de changer txt\n",
        "txt = \"I hate you\"\n",
        "vec_txt = vectorizer(txt)\n",
        "print(\"Prédiction pour la phrase mise est :\", model.predict(np.expand_dims(vec_txt, 0)))\n",
        "print(\"Labels :\", data.columns[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483daae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Préparation des données de test pour évaluer l'accuracy\n",
        "x_test = np.expand_dims(vec_txt.numpy(), 0)\n",
        "y_test = [[1, 0, 0, 0, 0, 0]]\n",
        "for batch in test.as_numpy_iterator():\n",
        "    batch_x, batch_y = batch\n",
        "    x_test = np.concatenate((x_test, batch_x))\n",
        "    y_test = np.concatenate((y_test, batch_y))\n",
        "yhat = model.predict(x_test)\n",
        "yhat = (yhat > 0.5).astype(int)\n",
        "print(\"Accuracy :\", accuracy_score(np.array(y_test).flatten(), yhat.flatten()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-metal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
